{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGKCXbWIVjT6"
   },
   "source": [
    "# Simulating Complex Physics with Graph Networks: step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1E_PEIxaHr8"
   },
   "source": [
    "## Overview\n",
    "\n",
    "• By Peng Chen, Shiyu Li, Haochen Shi as part of Stanford CS224W course project. \n",
    "\n",
    "• This tutorial provides a step-by-step guide for how to build a Graph Network to simulate complex physics.\n",
    "\n",
    "**Before we get started:**\n",
    "- This Colab includes a concise PyG implementation of paper ***Learning to Simulate Complex Physics with Graph Networks*.\n",
    "- We adapted our code from open-source tensorflow implementation by DeepMind.\n",
    "    - Link to pdf of this paper: https://arxiv.org/abs/2002.09405\n",
    "    - Link to Deepmind's implementation: https://github.com/deepmind/deepmind-research/tree/master/learning_to_simulate\n",
    "    - Link to video site by DeepMind: https://sites.google.com/view/learning-to-simulate\n",
    "- Run **sequentially run all cells in each section**, so intermediate variables / packages will carry over to next cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgi77SUya5RT"
   },
   "source": [
    "## Device\n",
    "\n",
    "We recommend using a GPU for this Colab. Click `Runtime` then `Change runtime type`. Then set `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPBthm7fHqNC"
   },
   "source": [
    "## Setup\n",
    "\n",
    "installation of PyG on Colab can be a little bit tricky. Before we get started, let's check which version of PyTorch you are running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGMo0gTp-GLe",
    "outputId": "1a45454d-a1a0-4ca7-8471-0a0919907b7f"
   },
   "outputs": [],
   "source": [
    "# Dataset Source #1:\n",
    "# https://drive.google.com/file/d/1ZmiKpsQVLFxPOIff-LfFkZwe5ZYG1FEb/view?usp=drive_link\n",
    "\n",
    "# Dataset Source #2:\n",
    "# https://drive.google.com/drive/mobile/folders/11uuYl0peqPg2DQno64YPYMODPu8fjDXU?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGMo0gTp-GLe",
    "outputId": "1a45454d-a1a0-4ca7-8471-0a0919907b7f"
   },
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGMo0gTp-GLe",
    "outputId": "1a45454d-a1a0-4ca7-8471-0a0919907b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.12.0+cu102 with cuda 10.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgnNePtAcNJu"
   },
   "source": [
    "• Download necessary packages for PyG. \n",
    "\n",
    "• ensure your version of torch matches output from cell above. \n",
    "\n",
    "• In case of any issues, more information may be found on [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS00k2JAKAzR",
    "outputId": "6d88f1c4-b8b5-4f1f-80c9-f0deb7e8ce87"
   },
   "source": [
    "!pip3 install torch==1.12.1+cu102 torchvision==0.13.1+cu102 torchaudio==0.12.1 torchtext --extra-index-url https://download.pytorch.org/whl/cu102\n",
    "\n",
    "!pip install https://data.pyg.org/whl/torch-1.12.0%2Bcu102/torch_cluster-1.6.0%2Bpt112cu102-cp37-cp37m-linux_x86_64.whl\n",
    "\n",
    "!pip install https://data.pyg.org/whl/torch-1.12.0%2Bcu102/torch_scatter-2.1.0%2Bpt112cu102-cp37-cp37m-linux_x86_64.whl\n",
    "\n",
    "!pip install https://data.pyg.org/whl/torch-1.12.0%2Bcu102/torch_sparse-0.6.16%2Bpt112cu102-cp37-cp37m-linux_x86_64.whl\n",
    "\n",
    "!pip install torch-geometric\n",
    "\n",
    "!pip install matplotlib\n",
    "\n",
    "!pip install networkx\n",
    "\n",
    "\n",
    "# Dataset Preparation\n",
    "!cd /home/admin1/Desktop/gnndataset/datasets/WaterDrop/\n",
    "\n",
    "# metadata.json\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1o6cKxgbnfUUFPTX1JngBzB928w2bUIwk' -O metadata.json\n",
    "\n",
    "# test_offset.json\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1vr4JiVliKCQNWVV4kziyusxNVUvQuAYL' -O test_offset.json\n",
    "\n",
    "# test_particle_type.dat\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Z_r9ivdKqKZzVJG80gb2uY6JDVRd0wAt' -O test_particle_type.dat\n",
    "\n",
    "# test_position.dat\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wCeBz1pZ5hxmlqWw4eylajg6pzFgQjIJ' -O test_position.dat\n",
    "\n",
    "# train_offset.json\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=160wnp9PEc1HuzsBi7kO0ryMu3tnon2tI' -O train_offset.json\n",
    "\n",
    "# train_particle_type.dat\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1LVtGLld7assF4sPk0mF2Bz2F7FBaxU0O' -O train_particle_type.dat\n",
    "\n",
    "# train_position.dat\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YCXcir_fmJZLvXkbPjchsrr8VuuWugH0' -O train_position.dat\n",
    "\n",
    "# valid_offset.json\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1tiDP5uHMJQDTNxyRNSb6sEZCWAADPu8a' -O valid_offset.json\n",
    "\n",
    "# valid_particle_type.dat\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1fXIw9RWM0xzfK2sGn1H0DaAOxzm59ZEd' -O valid_particle_type.dat\n",
    "\n",
    "# valid_position.dat\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1U9QuV3Ra0E1tDD1HgXYCYyn4SeLKXQGs' -O valid_position.dat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z4HbK-OPUK8"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "• Dataset WaterDropSmall includes 100 videos of dropping water to ground rendered in a particle-based physics simulator. \n",
    "\n",
    "• It is a cropped version of WaterDrop dataset by Deepmind. \n",
    "\n",
    "• will download this dataset from Google Cloud stoarge to folder `temp/datasets` in file system. \n",
    "\n",
    "• may inspect downloaded files on **Files** menu on left of this Colab.\n",
    "\n",
    "`metadata.json` file in dataset includes following information:\n",
    "1. sequence length of each video data point\n",
    "2. dimensionality, 2d or 3d\n",
    "3. box bounds - specify bounding box for scene\n",
    "4. default connectivity radius - defines size of each particle's neighborhood\n",
    "5. statistics for normalization e.g. velocity mean and standard deviation and acceleration of particles\n",
    "\n",
    "\n",
    "Each data point in dataset includes following information:\n",
    "1. Particle type, such as water\n",
    "2. particle positions at each frame in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxevKO1yPb4d",
    "outputId": "d4f3df44-fc86-4822-bb36-ca383dfc235d"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import inspect\n",
    "# Global flags to enable/disable debugging and verbosity\n",
    "DEBUG_ENABLED = True\n",
    "VERBOSE_ENABLED = False\n",
    "\n",
    "def debug_log(theVariable, functionName=None, ShowShape=False, ShowLength=False, ShowType=False, ExplicitVariableName=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    frame = inspect.currentframe().f_back\n",
    "    variable_names = [name for name, val in frame.f_locals.items() if val is theVariable]\n",
    "    # theVariableName = variable_names[0]\n",
    "    theVariableName = variable_names[0] if variable_names else ExplicitVariableName\n",
    "    \n",
    "\n",
    "#     if theVariableName == \"unknown_variable\":\n",
    "#         frame_info = traceback.extract_stack(limit=2)[0]\n",
    "#         log_message = f\"[{timestamp}] - Variable name unknown in {frame_info.filename} at line {frame_info.lineno}\\n\"\n",
    "#     else:\n",
    "#         log_message = f\"[{timestamp}] - {theVariableName}\\n\"\n",
    "        \n",
    "    \n",
    "    if DEBUG_ENABLED:\n",
    "        # INCLUDE functionName\n",
    "        if functionName:\n",
    "            log_message = f\"[{timestamp}] - {theVariableName} - {functionName}\\n\"\n",
    "        else:\n",
    "            # EXCLUDE functionName\n",
    "            log_message = f\"[{timestamp}] - {theVariableName}\\n\"\n",
    "            \n",
    "        if ShowShape:\n",
    "            log_message += \"Shape:\" + str(theVariable.shape) + \"\\n\"\n",
    "        if ShowLength:\n",
    "            if isinstance(theVariable, torch.Tensor):\n",
    "                if theVariable.dim() == 1:\n",
    "                    log_message += \"Length:\" + str(len(theVariable)) + \"\\n\"\n",
    "                else:\n",
    "                    length = theVariable.numel()\n",
    "                    log_message += \"Length:\" + str(length) + \"\\n\"\n",
    "            else:\n",
    "                log_message += \"Length:\" + str(len(theVariable)) + \"\\n\"\n",
    "        if ShowType:\n",
    "            if isinstance(theVariable, torch.Tensor):\n",
    "                log_message += \"Type:\" + str(theVariable.dtype) + \"\\n\"\n",
    "            else:\n",
    "                log_message += \"Type:\" + str(type(theVariable)) + \"\\n\"\n",
    "\n",
    "        # VARIABLE CONTENTS\n",
    "        log_message += str(theVariable) + \"\\n\"\n",
    "        log_message += \"---------------------------------------------------------\" + \"\\n\"\n",
    "            \n",
    "        # Get the current date and time\n",
    "        current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # with open('debugGNN.txt', 'a') as file:\n",
    "        with open(f'debugGNN_{current_date}.txt', 'a') as file:\n",
    "            file.write(log_message)\n",
    "\n",
    "    \n",
    "    if VERBOSE_ENABLED:\n",
    "        print(timestamp)\n",
    "        \n",
    "        if ShowShape:\n",
    "            print(\"Shape:\", theVariable.shape)\n",
    "        if ShowLength:\n",
    "            if isinstance(theVariable, torch.Tensor):\n",
    "                if theVariable.dim() == 1:\n",
    "                    print(\"Length:\", str(len(theVariable)))\n",
    "                else:\n",
    "                    length = theVariable.numel()\n",
    "                    print(\"Length:\", str(length))\n",
    "            else:\n",
    "                print(\"Length:\", str(len(theVariable)))                    \n",
    "        if ShowType:\n",
    "            if isinstance(theVariable, torch.Tensor):\n",
    "                print(\"Type:\", str(theVariable.dtype))  \n",
    "            else:\n",
    "                print(\"Type:\", str(type(theVariable))) \n",
    "\n",
    "        # VARIABLE CONTENTS                \n",
    "        if functionName:\n",
    "            print('#' * len(\"## \" + theVariableName + ' ## ' + functionName + \" ##\"))\n",
    "            print(\"## \" + theVariableName + ' ## ' + functionName + \" ##\")\n",
    "            print('#' * len(\"## \" + theVariableName + ' ## ' + functionName + \" ##\"))            \n",
    "            print(str(theVariable))\n",
    "        else:\n",
    "            print('#' * len(\"## \" + theVariableName + \" ##\"))\n",
    "            print(\"## \" + theVariableName + \" ##\")\n",
    "            print('#' * len(\"## \" + theVariableName + \" ##\"))            \n",
    "            print(str(theVariable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxevKO1yPb4d",
    "outputId": "d4f3df44-fc86-4822-bb36-ca383dfc235d"
   },
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "abc = 123\n",
    "debug_log(abc, ShowShape=False,ShowLength=False,ShowType=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxevKO1yPb4d",
    "outputId": "d4f3df44-fc86-4822-bb36-ca383dfc235d"
   },
   "outputs": [],
   "source": [
    "def debug_log_special(var):\n",
    "    # Use inspect to find the variable name in the caller's frame\n",
    "    frame = inspect.currentframe()\n",
    "    try:\n",
    "        caller_locals = frame.f_back.f_locals\n",
    "        var_name = [name for name, value in caller_locals.items() if value is var]\n",
    "        var_name = var_name[0] if var_name else \"unknown\"\n",
    "    finally:\n",
    "        del frame  # Clean up the frame to avoid reference cycles\n",
    "\n",
    "    # Print the variable name and its content\n",
    "    print(f\"{var_name}: {var}\")    \n",
    "    \n",
    "    with open('debugGNN1.txt', 'a') as file:\n",
    "        file.write(f\"{var_name}: {var}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxevKO1yPb4d",
    "outputId": "d4f3df44-fc86-4822-bb36-ca383dfc235d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.12.0+cu102 with cuda 10.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")\n",
    "\n",
    "DATASET_NAME = \"WaterDrop\"\n",
    "OUTPUT_DIR = os.path.join(\"/home/admin1/Desktop/GNN/gnndataset/datasets/WaterDrop\")\n",
    "\n",
    "debug_log(DATASET_NAME, ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "debug_log(OUTPUT_DIR, ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "# BASE_URL = f\"https://storage.googleapis.com/cs224w_course_project_dataset/{DATASET_NAME}\"\n",
    "\n",
    "# !mkdir -p \"$OUTPUT_DIR\"\n",
    "\n",
    "# META_DATA_PATH = f\"{OUTPUT_DIR}/metadata.json\"\n",
    "# CLOUD_PATH = f\"{BASE_URL}/metadata.json\"\n",
    "# !wget -O \"$META_DATA_PATH\" \"$CLOUD_PATH\"\n",
    "# for split in [\"test\", \"train\", \"valid\"]:\n",
    "#   for suffix in [\"offset.json\", \"particle_type.dat\", \"position.dat\"]:\n",
    "#       DATA_PATH = f\"{OUTPUT_DIR}/{split}_{suffix}\"\n",
    "#       CLOUD_PATH = f\"{BASE_URL}/{split}_{suffix}\"\n",
    "#       !wget -O \"$DATA_PATH\" \"$CLOUD_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW0_YsEPG68T"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "• Cannot apply raw data in dataset to train GNN model directly, so must perform below steps to convert raw data into graphs with descriptive node features and edge features:\n",
    "1. Apply noise to trajectory to have more diverse training examples\n",
    "1. Construct graph based on distance between particles\n",
    "1. Extract node-level features: particle velocities and their distance to boundary\n",
    "1. Extract edge-level features: displacement and distance between particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aCy3zaaOGrrS"
   },
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=/home/admin1/anaconda3/envs/GNN/lib:$LD_LIBRARY_PATH\n",
    "!export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aCy3zaaOGrrS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/GNN/lib/python3.10/site-packages/torch_cluster/nearest.py:4: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch_geometric as pyg\n",
    "\n",
    "def generate_noise(position_seq, noise_std):\n",
    "    \"\"\"Generate noise for a trajectory\"\"\"\n",
    "    velocity_seq = position_seq[:, 1:] - position_seq[:, :-1]\n",
    "    debug_log(velocity_seq, \"generate_noise\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "    time_steps = velocity_seq.size(1)\n",
    "    debug_log(time_steps, \"generate_noise\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    velocity_noise = torch.randn_like(velocity_seq) * (noise_std / time_steps ** 0.5)\n",
    "    debug_log(velocity_noise, \"generate_noise\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    velocity_noise = velocity_noise.cumsum(dim=1)\n",
    "    debug_log(velocity_noise, \"generate_noise\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    position_noise = velocity_noise.cumsum(dim=1)\n",
    "    debug_log(position_noise, \"generate_noise\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    position_noise = torch.cat((torch.zeros_like(position_noise)[:, 0:1], position_noise), dim=1)\n",
    "    debug_log(position_noise, \"generate_noise\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    return position_noise\n",
    "\n",
    "\n",
    "def preprocess(particle_type, position_seq, target_position, metadata, noise_std):\n",
    "    \"\"\"Preprocess a trajectory and construct graph\"\"\"\n",
    "    # apply noise to trajectory\n",
    "    position_noise = generate_noise(position_seq, noise_std)\n",
    "    debug_log(position_noise, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    position_seq = position_seq + position_noise\n",
    "    debug_log(position_seq, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "    # calculate velocities of particles\n",
    "    recent_position = position_seq[:, -1]\n",
    "    debug_log(recent_position, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    velocity_seq = position_seq[:, 1:] - position_seq[:, :-1]\n",
    "    debug_log(velocity_seq, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    # construct graph based on distances between particles\n",
    "    n_particle = recent_position.size(0)\n",
    "    debug_log(n_particle, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    edge_index = pyg.nn.radius_graph(recent_position, metadata[\"default_connectivity_radius\"], loop=True, max_num_neighbors=n_particle)\n",
    "    debug_log(edge_index, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "    \n",
    "    # node-level features: velocity, distance to boundary\n",
    "    normal_velocity_seq = (velocity_seq - torch.tensor(metadata[\"vel_mean\"])) / torch.sqrt(torch.tensor(metadata[\"vel_std\"]) ** 2 + noise_std ** 2)\n",
    "    debug_log(normal_velocity_seq, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    boundary = torch.tensor(metadata[\"bounds\"])\n",
    "    debug_log(boundary, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    \n",
    "    distance_to_lower_boundary = recent_position - boundary[:, 0]\n",
    "    debug_log(distance_to_lower_boundary, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "    \n",
    "    distance_to_upper_boundary = boundary[:, 1] - recent_position\n",
    "    debug_log(distance_to_upper_boundary, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "    \n",
    "    \n",
    "    distance_to_boundary = torch.cat((distance_to_lower_boundary, distance_to_upper_boundary), dim=-1)\n",
    "    debug_log(distance_to_boundary, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "    \n",
    "    \n",
    "    distance_to_boundary = torch.clip(distance_to_boundary / metadata[\"default_connectivity_radius\"], -1.0, 1.0)\n",
    "    debug_log(distance_to_boundary, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    # edge-level features: displacement, distance\n",
    "    dim = recent_position.size(-1)\n",
    "    debug_log(dim, \"preprocess\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "    \n",
    "    \n",
    "    edge_displacement = (torch.gather(recent_position, dim=0, index=edge_index[0].unsqueeze(-1).expand(-1, dim)) -\n",
    "                   torch.gather(recent_position, dim=0, index=edge_index[1].unsqueeze(-1).expand(-1, dim)))\n",
    "    debug_log(edge_displacement, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "    \n",
    "    \n",
    "    edge_displacement /= metadata[\"default_connectivity_radius\"]\n",
    "    debug_log(edge_displacement, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "    \n",
    "    \n",
    "    edge_distance = torch.norm(edge_displacement, dim=-1, keepdim=True)\n",
    "    debug_log(edge_distance, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "\n",
    "    \n",
    "    # ground truth for training\n",
    "    if target_position is not None:\n",
    "        last_velocity = velocity_seq[:, -1]\n",
    "        debug_log(last_velocity, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        next_velocity = target_position + position_noise[:, -1] - recent_position\n",
    "        debug_log(next_velocity, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        acceleration = next_velocity - last_velocity\n",
    "        debug_log(acceleration, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        acceleration = (acceleration - torch.tensor(metadata[\"acc_mean\"])) / torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise_std ** 2)\n",
    "        debug_log(acceleration, \"preprocess\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        acceleration = None\n",
    "\n",
    "    # return graph with features\n",
    "    graph = pyg.data.Data(\n",
    "        x=particle_type,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=torch.cat((edge_displacement, edge_distance), dim=-1),\n",
    "        y=acceleration,\n",
    "        pos=torch.cat((velocity_seq.reshape(velocity_seq.size(0), -1), distance_to_boundary), dim=-1)\n",
    "    )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqfx4NcguDEY"
   },
   "source": [
    "### One Step Dataset\n",
    "\n",
    "• Each datapoint in this dataset contains trajectories sliced to short time windows. \n",
    "\n",
    "• We use this dataset in training phase because history of particles' states are necessary for model to make predictions. \n",
    "\n",
    "• But in meantime, since long-horizon prediction is inaccurate and time-consuming, sliced trajectories to short time windows to improve perfomance of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b2HrUjPnsF_4"
   },
   "outputs": [],
   "source": [
    "class OneStepDataset(pyg.data.Dataset):\n",
    "    def __init__(self, data_path, split, window_length=7, noise_std=0.0, return_pos=False):\n",
    "        super().__init__()\n",
    "\n",
    "        debug_log(data_path, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "        \n",
    "        # load dataset from disk\n",
    "        with open(os.path.join(data_path, \"metadata.json\")) as f:\n",
    "            self.metadata = json.load(f)\n",
    "            debug_log(self.metadata, \"OneStepDataset\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.metadata\")        \n",
    "            \n",
    "        with open(os.path.join(data_path, f\"{split}_offset.json\")) as f:\n",
    "            self.offset = json.load(f)\n",
    "            # debug_log(self.offset, \"OneStepDataset 1\", ShowShape=False, ShowLength=True, ShowType=True)        \n",
    "            debug_log(self.offset, \"OneStepDataset 1\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.offset\")            \n",
    "            \n",
    "        self.offset = {int(k): v for k, v in self.offset.items()}\n",
    "        # debug_log(self.offset, \"OneStepDataset 2\", ShowShape=False, ShowLength=True, ShowType=True)        \n",
    "        debug_log(self.offset, \"OneStepDataset 2\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.offset\")        \n",
    "        \n",
    "        self.window_length = window_length\n",
    "        debug_log(window_length, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True)        \n",
    "        \n",
    "        \n",
    "        self.noise_std = noise_std\n",
    "        debug_log(noise_std, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True)        \n",
    "        \n",
    "        self.return_pos = return_pos\n",
    "        debug_log(return_pos, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True)        \n",
    "        \n",
    "\n",
    "        self.particle_type = np.memmap(os.path.join(data_path, f\"{split}_particle_type.dat\"), dtype=np.int64, mode=\"r\")\n",
    "        # debug_log(self.particle_type, \"OneStepDataset\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        debug_log(self.particle_type, \"OneStepDataset\", ShowShape=True, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.particle_type\")\n",
    "        \n",
    "        self.position = np.memmap(os.path.join(data_path, f\"{split}_position.dat\"), dtype=np.float32, mode=\"r\")\n",
    "        # debug_log(self.position, \"OneStepDataset\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        debug_log(self.position, \"OneStepDataset\", ShowShape=True, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.position\")\n",
    "        \n",
    "        for traj in self.offset.values():\n",
    "            self.dim = traj[\"position\"][\"shape\"][2]\n",
    "            # debug_log(self.dim, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "            debug_log(self.dim, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True, ExplicitVariableName = \"self.dim\")            \n",
    "            \n",
    "            break\n",
    "\n",
    "        # cut particle trajectories according to time slices\n",
    "        self.windows = []\n",
    "        for traj in self.offset.values():\n",
    "            size = traj[\"position\"][\"shape\"][1]\n",
    "            debug_log(size, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True)            \n",
    "            \n",
    "            length = traj[\"position\"][\"shape\"][0] - window_length + 1\n",
    "            debug_log(length, \"OneStepDataset\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            for i in range(length):\n",
    "                desc = {\n",
    "                    \"size\": size,\n",
    "                    \"type\": traj[\"particle_type\"][\"offset\"],\n",
    "                    \"pos\": traj[\"position\"][\"offset\"] + i * size * self.dim,\n",
    "                }\n",
    "                self.windows.append(desc)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.windows)\n",
    "\n",
    "    def get(self, idx):\n",
    "        # load corresponding data for this time slice\n",
    "        window = self.windows[idx]\n",
    "        debug_log(window, \"get\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        size = window[\"size\"]\n",
    "        debug_log(size, \"get\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        \n",
    "        \n",
    "        particle_type = self.particle_type[window[\"type\"]: window[\"type\"] + size].copy()\n",
    "        debug_log(particle_type, \"get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        particle_type = torch.from_numpy(particle_type)\n",
    "        debug_log(particle_type, \"get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        position_seq = self.position[window[\"pos\"]: window[\"pos\"] + self.window_length * size * self.dim].copy()\n",
    "        debug_log(position_seq, \"get\", ShowShape=True, ShowLength=True, ShowType=True) \n",
    "        \n",
    "        position_seq.resize(self.window_length, size, self.dim)\n",
    "        debug_log(position_seq, \"get\", ShowShape=True, ShowLength=True, ShowType=True)       \n",
    "        \n",
    "        position_seq = position_seq.transpose(1, 0, 2)\n",
    "        debug_log(position_seq, \"get\", ShowShape=True, ShowLength=True, ShowType=True)      \n",
    "        \n",
    "        target_position = position_seq[:, -1]\n",
    "        debug_log(target_position, \"get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        position_seq = position_seq[:, :-1]\n",
    "        debug_log(position_seq, \"get\", ShowShape=True, ShowLength=True, ShowType=True)    \n",
    "        \n",
    "        target_position = torch.from_numpy(target_position)\n",
    "        debug_log(target_position, \"get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        position_seq = torch.from_numpy(position_seq)\n",
    "        debug_log(position_seq, \"get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "\n",
    "        # construct graph\n",
    "        with torch.no_grad():\n",
    "            graph = preprocess(particle_type, position_seq, target_position, self.metadata, self.noise_std)\n",
    "        if self.return_pos:\n",
    "            return graph, position_seq[:, -1]\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqhPcZeKthYq"
   },
   "source": [
    "### Rollout Dataset\n",
    "\n",
    "• Each datapoint in this dataset contains trajectories of particles over 1000 time frames. \n",
    "\n",
    "• This dataset used in evaluation phase to measure model's ability to make long-horizon predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kuk2Z-I8sFv7"
   },
   "outputs": [],
   "source": [
    "class RolloutDataset(pyg.data.Dataset):\n",
    "    def __init__(self, data_path, split, window_length=7):\n",
    "        super().__init__()\n",
    "\n",
    "        # load data from disk\n",
    "        with open(os.path.join(data_path, \"metadata.json\")) as f:\n",
    "            self.metadata = json.load(f)\n",
    "            # debug_log(self.metadata, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "            debug_log(self.metadata, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.metadata\")\n",
    "            \n",
    "        with open(os.path.join(data_path, f\"{split}_offset.json\")) as f:\n",
    "            self.offset = json.load(f)\n",
    "            # debug_log(self.offset, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "            debug_log(self.offset, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.offset\")            \n",
    "            \n",
    "        self.offset = {int(k): v for k, v in self.offset.items()}\n",
    "        # debug_log(self.offset, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "        debug_log(self.offset, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.offset\")        \n",
    "        \n",
    "        self.window_length = window_length\n",
    "        debug_log(window_length, \"RolloutDataset\\_init_\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        \n",
    "\n",
    "        self.particle_type = np.memmap(os.path.join(data_path, f\"{split}_particle_type.dat\"), dtype=np.int64, mode=\"r\")\n",
    "        # debug_log(self.particle_type, \"RolloutDataset\\_init_\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        debug_log(self.particle_type, \"RolloutDataset\\_init_\", ShowShape=True, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.particle_type\")        \n",
    "        \n",
    "        self.position = np.memmap(os.path.join(data_path, f\"{split}_position.dat\"), dtype=np.float32, mode=\"r\")\n",
    "        # debug_log(self.position, \"RolloutDataset\\_init_\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        debug_log(self.position, \"RolloutDataset\\_init_\", ShowShape=True, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.position\")\n",
    "        \n",
    "        for traj in self.offset.values():\n",
    "            self.dim = traj[\"position\"][\"shape\"][2]\n",
    "            break\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.offset)\n",
    "\n",
    "    def get(self, idx):\n",
    "        traj = self.offset[idx]\n",
    "        debug_log(traj, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        size = traj[\"position\"][\"shape\"][1]\n",
    "        debug_log(size, \"RolloutDataset\\get\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        \n",
    "        \n",
    "        time_step = traj[\"position\"][\"shape\"][0]\n",
    "        debug_log(time_step, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        particle_type = self.particle_type[traj[\"particle_type\"][\"offset\"]: traj[\"particle_type\"][\"offset\"] + size].copy()\n",
    "        debug_log(particle_type, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        particle_type = torch.from_numpy(particle_type)\n",
    "        debug_log(particle_type, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        position = self.position[traj[\"position\"][\"offset\"]: traj[\"position\"][\"offset\"] + time_step * size * self.dim].copy()\n",
    "        debug_log(position, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        position.resize(traj[\"position\"][\"shape\"])\n",
    "        debug_log(position, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        position = torch.from_numpy(position)\n",
    "        debug_log(position, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        data = {\"particle_type\": particle_type, \"position\": position}\n",
    "        debug_log(data, \"RolloutDataset\\get\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVjrldn4kD-P"
   },
   "source": [
    "### Visualize a graph in dataset\n",
    "\n",
    "• Each data point in dataset is a `pyg.data.Data` object which describes a graph. \n",
    "\n",
    "• explain contents of first data point, visualize graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "_4MJuOhjkTjx",
    "outputId": "6ef28c82-9055-43d5-ec66-19b70e8a3ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23 in /home/admin1/anaconda3/envs/GNN/lib/python3.10/site-packages (1.23.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlnk5URCF7pZ"
   },
   "source": [
    "## GNN Model\n",
    "\n",
    "We will walk through implementation of GNN model in this section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vsVI6epJcsn"
   },
   "source": [
    "### Helper class\n",
    "\n",
    "• first define a class for Multi-Layer Perceptron (MLP). \n",
    "\n",
    "• This class generates an MLP given width and depth of it. \n",
    "\n",
    "• Because MLPs are used in several places of GNN, this helper class will make code cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ht-upXnRo0dV"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch_scatter\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"Multi-Layer perceptron\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, layers, layernorm=True):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        # debug_log(self.layers, \"MLP\\_init_\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "        debug_log(self.layers, \"MLP\\_init_\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.layers\")\n",
    "        \n",
    "        for i in range(layers):\n",
    "            self.layers.append(torch.nn.Linear(\n",
    "                input_size if i == 0 else hidden_size,\n",
    "                output_size if i == layers - 1 else hidden_size,\n",
    "            ))\n",
    "            \n",
    "            \n",
    "            if i != layers - 1:\n",
    "                self.layers.append(torch.nn.ReLU())\n",
    "                # debug_log(self.layers, \"MLP\\_init_\\i\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "                debug_log(self.layers, \"MLP\\_init_\\i\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.layers\")\n",
    "                \n",
    "        if layernorm:\n",
    "            self.layers.append(torch.nn.LayerNorm(output_size))\n",
    "            # debug_log(self.layers, \"MLP\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "            debug_log(self.layers, \"MLP\", ShowShape=False, ShowLength=True, ShowType=True, ExplicitVariableName = \"self.layers\")            \n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        \n",
    "        for layer in self.layers:\n",
    "            debug_log(layer, \"MLP\\reset_parameters\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "            \n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                layer.weight.data.normal_(0, 1 / math.sqrt(layer.in_features))\n",
    "                debug_log(layer, \"MLP\\reset_parameters\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "                \n",
    "                \n",
    "                layer.bias.data.fill_(0)\n",
    "                debug_log(layer, \"MLP\\reset_parameters\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_pkzDgqJ_ED"
   },
   "source": [
    "### GNN layers\n",
    "\n",
    "In following code block, we implement one type of GNN layer named `InteractionNetwork` (IN), which is proposed by paper *Interaction Networks for Learning about Objects,\n",
    "Relations and Physics*.\n",
    "\n",
    "• For a graph $G$, let feature of node $i$ be $v_i$, feature of edge $(i, j)$ be $e_{i, j}$. \n",
    "\n",
    "• three stages for IN to generate new features of nodes and edges.\n",
    "\n",
    "1. **Message generation.**\n",
    "\n",
    "• If there is an edge pointing from node $i$ to node $j$, node $i$ sends a message to node $j$. \n",
    "\n",
    "• message carries information of edge and its two nodes, so it is generated by following equation $\\mathrm{Msg}_{i,j} = \\mathrm{MLP}(v_i, v_j, e_{i,j})$.\n",
    "\n",
    "2. **Message aggregation.**\n",
    "\n",
    "• In this stage, each node of graph aggregates all messages it received to a fixed-sized representation. \n",
    "\n",
    "• In IN, aggregation means summing all messages up, i.e., $\\mathrm{Agg}_i=\\sum_{(j,i)\\in G}\\mathrm{Msg}_{i,j}$.\n",
    "\n",
    "3. **Update.**\n",
    "\n",
    "• update features of nodes and edges with results of previous stages. \n",
    "\n",
    "• For each edge, its new feature is sum of its old feature and correspond message, i.e., $e'_{i,j}=e_{i,j}+\\mathrm{Msg}_{i,j}$. \n",
    "\n",
    "• For each node, new feature is determined by its old feature and aggregated message, i.e., $v'_i=v_i+\\mathrm{MLP}(v_i, \\mathrm{Agg}_i)$.\n",
    "\n",
    "• In PyG, GNN layers are implemented as subclass of `MessagePassing`. \n",
    "\n",
    "• must override three critical functions to implement `InteractionNetwork` GNN layer. \n",
    "\n",
    "• Each function corresponds to one stage of GNN layer.\n",
    "\n",
    "1. `message()` -> message generation\n",
    "\n",
    "• This function controls how a message is generated on each edge of graph. \n",
    "\n",
    "• It takes three arguments:\n",
    "\n",
    "• (1) `x_i`, features of source nodes; \n",
    "\n",
    "• (2) `x_j`, features of target nodes; \n",
    "\n",
    "• (3) `edge_feature`, features of edges themselves. \n",
    "\n",
    "• In IN, concatenate all these features and generate messages with an MLP.\n",
    "\n",
    "1. `aggregate()` -> message aggregation\n",
    "\n",
    "• This function aggregates messages for nodes. \n",
    "\n",
    "• It depends on two arguments:\n",
    "\n",
    "• (1) `inputs`, messages; \n",
    "\n",
    "• (2) `index`, graph structure. \n",
    "\n",
    "• handle over task of message aggregation to function `torch_scatter.scatter` and specifies in argument `reduce` that want to sum messages up. \n",
    "\n",
    "• Because want to retain messages themselves to update edge features, return both messages and aggregated messages.\n",
    "\n",
    "1. `forward()` -> update\n",
    "\n",
    "• This function puts everything together. \n",
    "\n",
    "• `x` is node features, `edge_index` is graph structure and `edge_feature` is edge features. \n",
    "\n",
    "• function`MessagePassing.propagate` invokes functions `message` and `aggregate` for us. \n",
    "\n",
    "• Then, update node features and edge features and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nobE0LcXJ6RR"
   },
   "outputs": [],
   "source": [
    "class InteractionNetwork(pyg.nn.MessagePassing):\n",
    "    \"\"\"Interaction Network as proposed in this paper:\n",
    "    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n",
    "    def __init__(self, hidden_size, layers):\n",
    "        super().__init__()\n",
    "        self.lin_edge = MLP(hidden_size * 3, hidden_size, hidden_size, layers)\n",
    "        self.lin_node = MLP(hidden_size * 2, hidden_size, hidden_size, layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_feature):\n",
    "        edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_feature=edge_feature)\n",
    "        debug_log(edge_out, \"InteractionNetwork\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        node_out = self.lin_node(torch.cat((x, aggr), dim=-1))\n",
    "        debug_log(node_out, \"InteractionNetwork\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        edge_out = edge_feature + edge_out\n",
    "        debug_log(edge_out, \"InteractionNetwork\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        node_out = x + node_out\n",
    "        debug_log(node_out, \"InteractionNetwork\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        return node_out, edge_out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_feature):\n",
    "        x = torch.cat((x_i, x_j, edge_feature), dim=-1)\n",
    "        debug_log(x, \"InteractionNetwork\\message\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        x = self.lin_edge(x)\n",
    "        debug_log(x, \"InteractionNetwork\\message\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        out = torch_scatter.scatter(inputs, index, dim=self.node_dim, dim_size=dim_size, reduce=\"sum\")\n",
    "        debug_log(out, \"InteractionNetwork\\aggregate\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        return (inputs, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Aa9znXKH40"
   },
   "source": [
    "### GNN\n",
    "\n",
    "• Now its time to stack GNN layers to a GNN. \n",
    "\n",
    "• Besides GNN layers, pre-processing and post-processing blocks in GNN. \n",
    "\n",
    "• Before GNN layers, input features are transformed by MLP so expressiveness of GNN is improved without increasing GNN layers. \n",
    "\n",
    "• After GNN layers, final outputs (accelerations of particles in case) are extracted from features generated by GNN layers to meet requirement of task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZoB4_A6YJ7FP"
   },
   "outputs": [],
   "source": [
    "class LearnedSimulator(torch.nn.Module):\n",
    "    \"\"\"Graph Network-based Simulators(GNS)\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size=128,\n",
    "        n_mp_layers=10, # number of GNN layers\n",
    "        num_particle_types=9,\n",
    "        particle_type_dim=16, # embedding dimension of particle types\n",
    "        dim=2, # dimension of world, typical 2D or 3D\n",
    "        window_size=5, # model looks into W frames before frame to be predicted\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        debug_log(window_size, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "        \n",
    "        \n",
    "        self.embed_type = torch.nn.Embedding(num_particle_types, particle_type_dim)\n",
    "        # debug_log(self.embed_type, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        debug_log(self.embed_type, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True, ExplicitVariableName = \"self.embed_type\")        \n",
    "        \n",
    "        self.node_in = MLP(particle_type_dim + dim * (window_size + 2), hidden_size, hidden_size, 3)\n",
    "        # debug_log(self.node_in, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        debug_log(self.node_in, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True, ExplicitVariableName = \"self.node_in\")        \n",
    "        \n",
    "        self.edge_in = MLP(dim + 1, hidden_size, hidden_size, 3)\n",
    "        # debug_log(self.node_in, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        debug_log(self.edge_in, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True, ExplicitVariableName = \"self.edge_in\")        \n",
    "        \n",
    "        self.node_out = MLP(hidden_size, hidden_size, dim, 3, layernorm=False)\n",
    "        # debug_log(self.node_out, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        debug_log(self.node_out, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True, ExplicitVariableName = \"self.node_out\")        \n",
    "        \n",
    "        self.n_mp_layers = n_mp_layers\n",
    "        debug_log(n_mp_layers, \"LearnedSimulator\\_init_\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "        \n",
    "        \n",
    "        self.layers = torch.nn.ModuleList([InteractionNetwork(\n",
    "            hidden_size, 3\n",
    "        ) for _ in range(n_mp_layers)])\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embed_type.weight)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # pre-processing\n",
    "        # node feature: combine categorial feature data.x and contiguous feature data.pos.\n",
    "        node_feature = torch.cat((self.embed_type(data.x), data.pos), dim=-1)\n",
    "        debug_log(node_feature, \"LearnedSimulator\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        node_feature = self.node_in(node_feature)\n",
    "        debug_log(node_feature, \"LearnedSimulator\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        edge_feature = self.edge_in(data.edge_attr)\n",
    "        debug_log(edge_feature, \"LearnedSimulator\\forward\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "        \n",
    "        \n",
    "        # stack of GNN layers\n",
    "        for i in range(self.n_mp_layers):\n",
    "            node_feature, edge_feature = self.layers[i](node_feature, data.edge_index, edge_feature=edge_feature)\n",
    "            debug_log(node_feature, \"LearnedSimulator\\forward\\i\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "            debug_log(edge_feature, \"LearnedSimulator\\forward\\i\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "            \n",
    "            \n",
    "        # post-processing\n",
    "        out = self.node_out(node_feature)\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7LUIouahvhW"
   },
   "source": [
    "## Training\n",
    "\n",
    "• Before start training model, let's configure hyperparameters! \n",
    "\n",
    "• Since accessible computaion power is limited in Colab, will only run 1 epoch of training, which takes about 1.5 hour. \n",
    "\n",
    "• won't produce as accurate results as shown in original paper in this Colab. \n",
    "\n",
    "• provide a checkpoint of training model on entire WaterDrop dataset for 5 epochs, which takes about 14 hours with a GeForce RTX 3080 Ti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Czpr3hJTiCuC"
   },
   "outputs": [],
   "source": [
    "data_path = OUTPUT_DIR\n",
    "debug_log(data_path, ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "model_path = os.path.join(\"temp\", \"models\", DATASET_NAME)\n",
    "debug_log(model_path, ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "rollout_path = os.path.join(\"temp\", \"rollouts\", DATASET_NAME)\n",
    "debug_log(rollout_path, ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "!mkdir -p \"$model_path\"\n",
    "!mkdir -p \"$rollout_path\"\n",
    "\n",
    "params = {\n",
    "    #\"epoch\": 1,\n",
    "    \"epoch\": 20,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    \"noise\": 3e-4,\n",
    "    \"save_interval\": 1000,\n",
    "    \"eval_interval\": 1000,\n",
    "    \"rollout_interval\": 200000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN_P6D4tK7FQ"
   },
   "source": [
    "Below are some helper functions for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OSIAlxN7KvuZ"
   },
   "outputs": [],
   "source": [
    "def rollout(model, data, metadata, noise_std):\n",
    "    device = next(model.parameters()).device\n",
    "    debug_log(device, \"rollout\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    window_size = model.window_size + 1\n",
    "    debug_log(window_size, \"rollout\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "   \n",
    "    total_time = data[\"position\"].size(0)\n",
    "    debug_log(total_time, \"rollout\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    traj = data[\"position\"][:window_size]\n",
    "    debug_log(traj, \"rollout\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    traj = traj.permute(1, 0, 2)\n",
    "    debug_log(traj, \"rollout\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "    \n",
    "    particle_type = data[\"particle_type\"]\n",
    "    debug_log(particle_type, \"rollout\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "    for time in range(total_time - window_size):\n",
    "        with torch.no_grad():\n",
    "            graph = preprocess(particle_type, traj[:, -window_size:], None, metadata, 0.0)\n",
    "            debug_log(graph, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            graph = graph.to(device)\n",
    "            debug_log(graph, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            acceleration = model(graph).cpu()\n",
    "            debug_log(acceleration, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            acceleration = acceleration * torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise_std ** 2) + torch.tensor(metadata[\"acc_mean\"])\n",
    "            debug_log(acceleration, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "                        \n",
    "\n",
    "            recent_position = traj[:, -1]\n",
    "            debug_log(recent_position, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            recent_velocity = recent_position - traj[:, -2]\n",
    "            debug_log(recent_velocity, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            new_velocity = recent_velocity + acceleration\n",
    "            debug_log(new_velocity, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            new_position = recent_position + new_velocity\n",
    "            debug_log(new_position, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            traj = torch.cat((traj, new_position.unsqueeze(1)), dim=1)\n",
    "            debug_log(traj, \"rollout\\time\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "def oneStepMSE(simulator, dataloader, metadata, noise):\n",
    "    \"\"\"Returns two values, loss and MSE\"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "    batch_count = 0\n",
    "    simulator.eval()\n",
    "    with torch.no_grad():\n",
    "        scale = torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise ** 2).cuda()\n",
    "        for data in valid_loader:\n",
    "            data = data.cuda()\n",
    "            debug_log(data, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            pred = simulator(data)\n",
    "            debug_log(pred, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            mse = ((pred - data.y) * scale) ** 2\n",
    "            debug_log(mse, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            mse = mse.sum(dim=-1).mean()\n",
    "            debug_log(mse, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            loss = ((pred - data.y) ** 2).mean()\n",
    "            debug_log(loss, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            total_mse += mse.item()\n",
    "            debug_log(total_mse, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            debug_log(total_loss, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "           \n",
    "            \n",
    "            batch_count += 1\n",
    "            debug_log(batch_count, \"oneStepMSE\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "    return total_loss / batch_count, total_mse / batch_count\n",
    "\n",
    "\n",
    "def rolloutMSE(simulator, dataset, noise):\n",
    "    total_loss = 0.0\n",
    "    batch_count = 0\n",
    "    simulator.eval()\n",
    "    with torch.no_grad():\n",
    "        for rollout_data in dataset:\n",
    "            debug_log(rollout_data, \"rolloutMSE\\rollout_data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "            \n",
    "            rollout_out = rollout(simulator, rollout_data, dataset.metadata, noise)\n",
    "            debug_log(rollout_out, \"rolloutMSE\\rollout_data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "            \n",
    "            \n",
    "            rollout_out = rollout_out.permute(1, 0, 2)\n",
    "            debug_log(rollout_out, \"rolloutMSE\\rollout_data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "            \n",
    "            \n",
    "            loss = (rollout_out - rollout_data[\"position\"]) ** 2\n",
    "            debug_log(loss, \"rolloutMSE\\rollout_data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            loss = loss.sum(dim=-1).mean()\n",
    "            debug_log(loss, \"rolloutMSE\\rollout_data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            debug_log(total_loss, \"rolloutMSE\\rollout_data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "            batch_count += 1\n",
    "            debug_log(batch_count, \"rolloutMSE\\rollout_data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "            \n",
    "            \n",
    "    return total_loss / batch_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwvseROOFqt0"
   },
   "source": [
    "Here is main training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oRsKEIX6XAwN"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(params, simulator, train_loader, valid_loader, valid_rollout_dataset):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    debug_log(loss_fn, \"train\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(simulator.parameters(), lr=params[\"lr\"])\n",
    "    debug_log(optimizer, \"train\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "       \n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1 ** (1 / 5e6))\n",
    "    debug_log(scheduler, \"train\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    # recording loss curve\n",
    "    train_loss_list = []\n",
    "    eval_loss_list = []\n",
    "    onestep_mse_list = []\n",
    "    rollout_mse_list = []\n",
    "    total_step = 0\n",
    "\n",
    "    for i in range(params[\"epoch\"]):\n",
    "        simulator.train()\n",
    "        \n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {i}\")\n",
    "        debug_log(progress_bar, \"train\\i\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "        \n",
    "        \n",
    "        total_loss = 0\n",
    "        debug_log(total_loss, \"train\\i\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "        \n",
    "        \n",
    "        batch_count = 0\n",
    "        debug_log(batch_count, \"train\\i\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for data in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            debug_log(optimizer, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=True)\n",
    "            \n",
    "            \n",
    "            data = data.cuda()\n",
    "            debug_log(data, \"train\\i\\data\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "            \n",
    "            \n",
    "            pred = simulator(data)\n",
    "            debug_log(pred, \"train\\i\\data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "            \n",
    "            \n",
    "            loss = loss_fn(pred, data.y)\n",
    "            debug_log(loss, \"train\\i\\data\", ShowShape=True, ShowLength=False, ShowType=True)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            debug_log(total_loss, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "            batch_count += 1\n",
    "            debug_log(batch_count, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "            progress_bar.set_postfix({\"loss\": loss.item(), \"avg_loss\": total_loss / batch_count, \"lr\": optimizer.param_groups[0][\"lr\"]})\n",
    "\n",
    "\n",
    "            total_step += 1\n",
    "            debug_log(total_step, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "            train_loss_list.append((total_step, loss.item()))\n",
    "            debug_log(train_loss_list, \"train\\i\\data\", ShowShape=False, ShowLength=True, ShowType=True)\n",
    "\n",
    "\n",
    "\n",
    "            # evaluation\n",
    "            if total_step % params[\"eval_interval\"] == 0:\n",
    "                simulator.eval()\n",
    "                eval_loss, onestep_mse = oneStepMSE(simulator, valid_loader, valid_dataset.metadata, params[\"noise\"])\n",
    "                debug_log(eval_loss, \"train\\i\\data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "\n",
    "\n",
    "                eval_loss_list.append((total_step, eval_loss))\n",
    "                debug_log(eval_loss_list, \"train\\i\\data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "\n",
    "\n",
    "                onestep_mse_list.append((total_step, onestep_mse))\n",
    "                debug_log(onestep_mse_list, \"train\\i\\data\", ShowShape=True, ShowLength=True, ShowType=True)\n",
    "\n",
    "\n",
    "\n",
    "                tqdm.write(f\"\\nEval: Loss: {eval_loss}, One Step MSE: {onestep_mse}\")\n",
    "                simulator.train()\n",
    "\n",
    "            # do rollout on valid set\n",
    "            if total_step % params[\"rollout_interval\"] == 0:\n",
    "                simulator.eval()\n",
    "                rollout_mse = rolloutMSE(simulator, valid_rollout_dataset, params[\"noise\"])\n",
    "                debug_log(rollout_mse, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "                rollout_mse_list.append((total_step, rollout_mse))\n",
    "                debug_log(rollout_mse_list, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "\n",
    "                tqdm.write(f\"\\nEval: Rollout MSE: {rollout_mse}\")\n",
    "                simulator.train()\n",
    "\n",
    "            # save model\n",
    "            if total_step % params[\"save_interval\"] == 0:\n",
    "                debug_log(total_step, \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "                debug_log(params[save_interval], \"train\\i\\data\", ShowShape=False, ShowLength=False, ShowType=False)\n",
    "\n",
    "                \n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model\": simulator.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                        \"scheduler\": scheduler.state_dict(),\n",
    "                    },\n",
    "                    os.path.join(model_path, f\"checkpoint_{total_step}.pt\")\n",
    "                )\n",
    "    return train_loss_list, eval_loss_list, onestep_mse_list, rollout_mse_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ-U-nlEakHF"
   },
   "source": [
    "• let's load dataset and train model! \n",
    "\n",
    "• It takes roughly 1.5 hour to run this block on Colab with default parameters. \n",
    "\n",
    "• **If you are impatient, highly recommend you to skip next 2 blocks and load checkpoint provided to save some time;**\n",
    "\n",
    "• **otherwise, make a cup of tea/coffee and come back later to see results of training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1HWNWqbE6db",
    "outputId": "fa143d3b-f28c-4484-d9cb-70c2f9b8ae63",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%| | 146/24875 [00:26<1:15:56,  5.43it/s, loss=0.936, avg_loss=1.03,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m simulator \u001b[38;5;241m=\u001b[39m simulator\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_loss_list, eval_loss_list, onestep_mse_list, rollout_mse_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_rollout_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, simulator, train_loader, valid_loader, valid_rollout_dataset)\u001b[0m\n\u001b[1;32m     45\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     46\u001b[0m debug_log(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, ShowShape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ShowLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m debug_log(pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, ShowShape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, data\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 63\u001b[0m, in \u001b[0;36mLearnedSimulator.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# stack of GNN layers\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_mp_layers):\n\u001b[0;32m---> 63\u001b[0m     node_feature, edge_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     debug_log(node_feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearnedSimulator\u001b[39m\u001b[38;5;130;01m\\f\u001b[39;00m\u001b[38;5;124morward\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, ShowShape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     debug_log(edge_feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearnedSimulator\u001b[39m\u001b[38;5;130;01m\\f\u001b[39;00m\u001b[38;5;124morward\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, ShowShape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m, in \u001b[0;36mInteractionNetwork.forward\u001b[0;34m(self, x, edge_index, edge_feature)\u001b[0m\n\u001b[1;32m     19\u001b[0m debug_log(edge_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInteractionNetwork\u001b[39m\u001b[38;5;130;01m\\f\u001b[39;00m\u001b[38;5;124morward\u001b[39m\u001b[38;5;124m\"\u001b[39m, ShowShape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ShowType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m node_out \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m node_out\n\u001b[0;32m---> 23\u001b[0m \u001b[43mdebug_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInteractionNetwork\u001b[39;49m\u001b[38;5;130;43;01m\\f\u001b[39;49;00m\u001b[38;5;124;43morward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mShowShape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mShowLength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mShowType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node_out, edge_out\n",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mdebug_log\u001b[0;34m(theVariable, functionName, ShowShape, ShowLength, ShowType, ExplicitVariableName)\u001b[0m\n\u001b[1;32m     46\u001b[0m         log_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(theVariable)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# VARIABLE CONTENTS\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m log_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtheVariable\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m log_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Get the current date and time\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/_tensor.py:338\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    336\u001b[0m                                  tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/_tensor_str.py:481\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_str\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/_tensor_str.py:447\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    445\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    446\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 447\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    450\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/_tensor_str.py:270\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/_tensor_str.py:142\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m nonzero_finite_vals:\n\u001b[0;32m--> 142\u001b[0m                 value_str \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m{{\u001b[39;49m\u001b[38;5;124;43m:.\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43mf}}\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PRINT_OPTS\u001b[38;5;241m.\u001b[39msci_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.10/site-packages/torch/_tensor.py:659\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta:\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training model is time-consuming. We highly recommend you to skip this block and load checkpoint in next block.\n",
    "\n",
    "# load dataset\n",
    "train_dataset = OneStepDataset(data_path, \"train\", noise_std=params[\"noise\"])\n",
    "debug_log(train_dataset, ShowShape=False, ShowLength=True, ShowType=True)\n",
    "\n",
    "valid_dataset = OneStepDataset(data_path, \"valid\", noise_std=params[\"noise\"])\n",
    "debug_log(valid_dataset, ShowShape=False, ShowLength=True, ShowType=True)\n",
    "\n",
    "train_loader = pyg.loader.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True, pin_memory=True, num_workers=2)\n",
    "debug_log(train_loader, ShowShape=False, ShowLength=True, ShowType=True)\n",
    "\n",
    "valid_loader = pyg.loader.DataLoader(valid_dataset, batch_size=params[\"batch_size\"], shuffle=False, pin_memory=True, num_workers=2)\n",
    "debug_log(valid_loader, ShowShape=False, ShowLength=True, ShowType=True)\n",
    "\n",
    "valid_rollout_dataset = RolloutDataset(data_path, \"valid\")\n",
    "debug_log(valid_rollout_dataset, ShowShape=False, ShowLength=True, ShowType=True)\n",
    "\n",
    "# build model\n",
    "simulator = LearnedSimulator()\n",
    "\n",
    "simulator = simulator.cuda()\n",
    "\n",
    "# train model\n",
    "train_loss_list, eval_loss_list, onestep_mse_list, rollout_mse_list = train(params, simulator, train_loader, valid_loader, valid_rollout_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MBw_qGjz62_S",
    "outputId": "f69959c9-a199-4e82-ea12-694112546893"
   },
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_save_path = \"simulator_model_manymanyepoch.pth\"\n",
    "\n",
    "\n",
    "torch.save(simulator.state_dict(), model_save_path)\n",
    "\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MBw_qGjz62_S",
    "outputId": "f69959c9-a199-4e82-ea12-694112546893"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize loss curve\n",
    "plt.figure()\n",
    "plt.plot(*zip(*train_loss_list), label=\"train\")\n",
    "plt.plot(*zip(*eval_loss_list), label=\"valid\")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y2Pf_TcbR0K"
   },
   "source": [
    "• Load checkpoint trained by us. \n",
    "\n",
    "• Do **not** run this block if you have trained your model in previous block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cw26wx-9B_Q3"
   },
   "outputs": [],
   "source": [
    "################\n",
    "## LOAD MODEL ##\n",
    "################\n",
    "simulator = LearnedSimulator()\n",
    "\n",
    "\n",
    "simulator = simulator.cuda()\n",
    "\n",
    "\n",
    "#!wget -O temp/models/WaterDrop_checkpoint.pt https://storage.googleapis.com/cs224w_course_project_dataset/Checkpoints/WaterDrop_checkpoint.pt\n",
    "# checkpoint = torch.load(\"simulator_model_20epoch.pth\")\n",
    "# simulator.load_state_dict(checkpoint[\"model\"])\n",
    "model_save_path = \"simulator_model_20epoch.pth\"\n",
    "\n",
    "\n",
    "simulator.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eDD-SySxKFt"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Since video is 1000 frames long, it might take a few minutes to rollout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNhrML1SrWIe"
   },
   "outputs": [],
   "source": [
    "rollout_dataset = RolloutDataset(data_path, \"valid\")\n",
    "\n",
    "\n",
    "simulator.eval()\n",
    "\n",
    "\n",
    "rollout_data = rollout_dataset[0]\n",
    "\n",
    "\n",
    "rollout_out = rollout(simulator, rollout_data, rollout_dataset.metadata, params[\"noise\"])\n",
    "\n",
    "\n",
    "rollout_out = rollout_out.permute(1, 0, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "H0W5Tm4rws0_",
    "outputId": "a9a21fec-2d17-4ab5-f37e-b7bf3fc05114"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "TYPE_TO_COLOR = {\n",
    "    3: \"black\",\n",
    "    0: \"green\",\n",
    "    7: \"magenta\",\n",
    "    6: \"gold\",\n",
    "    5: \"blue\",\n",
    "}\n",
    "\n",
    "\n",
    "def visualize_prepare(ax, particle_type, position, metadata):\n",
    "    bounds = metadata[\"bounds\"]\n",
    "    ax.set_xlim(bounds[0][0], bounds[0][1])\n",
    "    ax.set_ylim(bounds[1][0], bounds[1][1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1.0)\n",
    "    points = {type_: ax.plot([], [], \"o\", ms=2, color=color)[0] for type_, color in TYPE_TO_COLOR.items()}\n",
    "    return ax, position, points\n",
    "\n",
    "\n",
    "def visualize_pair(particle_type, position_pred, position_gt, metadata):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    plot_info = [\n",
    "        visualize_prepare(axes[0], particle_type, position_gt, metadata),\n",
    "        visualize_prepare(axes[1], particle_type, position_pred, metadata),\n",
    "    ]\n",
    "    axes[0].set_title(\"Ground truth\")\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    def update(step_i):\n",
    "        outputs = []\n",
    "\n",
    "\n",
    "        for _, position, points in plot_info:\n",
    "\n",
    "\n",
    "            for type_, line in points.items():\n",
    "                mask = particle_type == type_\n",
    "\n",
    "\n",
    "                line.set_data(position[step_i, mask, 0], position[step_i, mask, 1])\n",
    "\n",
    "\n",
    "            outputs.append(line)\n",
    "        return outputs\n",
    "\n",
    "    return animation.FuncAnimation(fig, update, frames=np.arange(0, position_gt.size(0)), interval=10, blit=True)\n",
    "\n",
    "anim = visualize_pair(rollout_data[\"particle_type\"], rollout_out, rollout_data[\"position\"], rollout_dataset.metadata)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3t753E3BzEC"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "• Hope this Colab is helpful for you to understand how to apply GNN in a real-world application like simulating complex physics! \n",
    "\n",
    "• If you're interested in technical details, read [medium post](https://) or see [original paper](https://arxiv.org/abs/2002.09405) by DeepMind. \n",
    "\n",
    "• Thanks for spending your time with us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
